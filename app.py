import os
import logging
from flask import Flask, request, jsonify
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import MessageEvent, TextMessage, TextSendMessage, QuickReply, QuickReplyButton, MessageAction
from collections import defaultdict
from datetime import datetime

# Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª
try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
    print("âš ï¸ Google Gemini not available")

try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    print("âš ï¸ OpenAI not available")

app = Flask(__name__)

# ========================
# Logging Setup
# ========================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ========================
# LINE API Configuration
# ========================
LINE_CHANNEL_ACCESS_TOKEN = os.environ.get("LINE_CHANNEL_ACCESS_TOKEN")
LINE_CHANNEL_SECRET = os.environ.get("LINE_CHANNEL_SECRET")

if not LINE_CHANNEL_ACCESS_TOKEN or not LINE_CHANNEL_SECRET:
    raise ValueError("âŒ ÙŠØ¬Ø¨ ØªØ¹ÙŠÙŠÙ† LINE_CHANNEL_ACCESS_TOKEN Ùˆ LINE_CHANNEL_SECRET")

line_bot_api = LineBotApi(LINE_CHANNEL_ACCESS_TOKEN)
handler = WebhookHandler(LINE_CHANNEL_SECRET)

# ========================
# AI Configuration
# ========================
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
GENAI_API_KEY = os.environ.get("GENAI_API_KEY")

# ØªÙ‡ÙŠØ¦Ø© OpenAI
openai_client = None
if OPENAI_API_KEY and OPENAI_AVAILABLE:
    try:
        openai_client = OpenAI(api_key=OPENAI_API_KEY)
        logger.info("âœ… OpenAI initialized successfully")
    except Exception as e:
        logger.error(f"âŒ OpenAI initialization failed: {e}")

# ØªÙ‡ÙŠØ¦Ø© Gemini
gemini_model = None
if GENAI_API_KEY and GEMINI_AVAILABLE:
    try:
        genai.configure(api_key=GENAI_API_KEY)
        gemini_model = genai.GenerativeModel('gemini-pro')
        logger.info("âœ… Gemini initialized successfully")
    except Exception as e:
        logger.error(f"âŒ Gemini initialization failed: {e}")

# ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ
DEFAULT_ENGINE = "openai" if openai_client else "gemini" if gemini_model else None

if not DEFAULT_ENGINE:
    raise ValueError("âŒ ÙŠØ¬Ø¨ ØªØ¹ÙŠÙŠÙ† OPENAI_API_KEY Ø£Ùˆ GENAI_API_KEY")

logger.info(f"ğŸ¤– Using {DEFAULT_ENGINE.upper()} as default engine")

# ========================
# Context Memory
# ========================
user_conversations = defaultdict(list)
user_preferences = defaultdict(lambda: {"engine": DEFAULT_ENGINE})

def add_to_context(user_id, message, response):
    """Ø­ÙØ¸ Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"""
    user_conversations[user_id].append({
        'user': message,
        'bot': response,
        'timestamp': datetime.now().isoformat()
    })
    if len(user_conversations[user_id]) > 5:
        user_conversations[user_id].pop(0)

def get_context(user_id):
    """Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"""
    if user_id in user_conversations:
        context = "\n".join([f"Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {c['user']}\nØ§Ù„Ø¨ÙˆØª: {c['bot']}" 
                            for c in user_conversations[user_id][-3:]])
        return f"\n\nØ§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø³Ø§Ø¨Ù‚:\n{context}\n\n"
    return ""

# ========================
# AI Response Generator
# ========================
def generate_with_openai(prompt, context=""):
    """ØªÙˆÙ„ÙŠØ¯ Ù…Ø­ØªÙˆÙ‰ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… OpenAI"""
    try:
        response = openai_client.chat.completions.create(
            model="gpt-4-turbo-preview",
            messages=[
                {"role": "system", "content": "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù…ØªØ®ØµØµ ÙÙŠ Ø§Ù„ØªØ¹Ù„ÙŠÙ… ÙˆØ§Ù„Ø¨Ø±Ù…Ø¬Ø© ÙˆØ§Ù„ØªØµÙ…ÙŠÙ…. ØªØ¬ÙŠØ¨ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø´ÙƒÙ„ Ø§Ø­ØªØ±Ø§ÙÙŠ ÙˆÙ…ÙÙŠØ¯."},
                {"role": "user", "content": context + prompt}
            ],
            temperature=0.7,
            max_tokens=2000
        )
        return response.choices[0].message.content
    except Exception as e:
        logger.error(f"OpenAI Error: {str(e)}")
        return None

def generate_with_gemini(prompt, context=""):
    """ØªÙˆÙ„ÙŠØ¯ Ù…Ø­ØªÙˆÙ‰ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini"""
    try:
        full_prompt = context + prompt
        response = gemini_model.generate_content(full_prompt)
        return response.text
    except Exception as e:
        logger.error(f"Gemini Error: {str(e)}")
        return None

def safe_generate_content(prompt, context_type="", user_id=None, engine=None):
    """ØªÙˆÙ„ÙŠØ¯ Ù…Ø­ØªÙˆÙ‰ Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ø®Ø·Ø§Ø¡ ÙˆØªØ¨Ø¯ÙŠÙ„ ØªÙ„Ù‚Ø§Ø¦ÙŠ"""
    # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø­Ø±Ùƒ
    if engine is None:
        engine = user_preferences[user_id]["engine"] if user_id else DEFAULT_ENGINE
    
    # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø³ÙŠØ§Ù‚
    context = get_context(user_id) if user_id else ""
    
    # Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø¹ Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ù…Ø­Ø¯Ø¯
    if engine == "openai" and openai_client:
        result = generate_with_openai(prompt, context)
        if result:
            return result
        # ÙØ´Ù„ OpenAIØŒ Ø¬Ø±Ø¨ Gemini
        logger.warning("OpenAI failed, trying Gemini...")
        if gemini_model:
            result = generate_with_gemini(prompt, context)
            if result:
                return result
    
    elif engine == "gemini" and gemini_model:
        result = generate_with_gemini(prompt, context)
        if result:
            return result
        # ÙØ´Ù„ GeminiØŒ Ø¬Ø±Ø¨ OpenAI
        logger.warning("Gemini failed, trying OpenAI...")
        if openai_client:
            result = generate_with_openai(prompt, context)
            if result:
                return result
    
    # ÙƒÙ„Ø§ Ø§Ù„Ù…Ø­Ø±ÙƒÙŠÙ† ÙØ´Ù„
    return f"âš ï¸ Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ù…Ø¤Ù‚Øª ÙÙŠ {context_type}. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰."

# ========================
# Helper Functions
# ========================

def HELP_TEXT():
    engines_status = []
    if openai_client:
        engines_status.append("OpenAI GPT-4")
    if gemini_model:
        engines_status.append("Google Gemini")
    
    engines = " + ".join(engines_status)
    
    return f"""ğŸ¤– **Ø§Ù„Ø¨ÙˆØª Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠ**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âš¡ Ø§Ù„Ù…Ø­Ø±ÙƒØ§Øª: {engines}

ğŸ¯ **Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©:**

1ï¸âƒ£ **Ù…Ø³Ø§Ø¹Ø¯Ø©** - Ø¹Ø±Ø¶ Ù‡Ø°Ù‡ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©
2ï¸âƒ£ **ØµÙˆØ±Ø© [ÙˆØµÙ]** - ÙˆØµÙ Ø§Ø­ØªØ±Ø§ÙÙŠ Ù„Ù„ØµÙˆØ±
3ï¸âƒ£ **ÙÙŠØ¯ÙŠÙˆ [Ù…ÙˆØ¶ÙˆØ¹]** - Ø¯Ù„ÙŠÙ„ Ø¥Ù†Ø´Ø§Ø¡ ÙÙŠØ¯ÙŠÙˆ
4ï¸âƒ£ **Ø¹Ø±Ø¶ [Ù…ÙˆØ¶ÙˆØ¹]** - Ø¹Ø±Ø¶ ØªÙ‚Ø¯ÙŠÙ…ÙŠ ÙƒØ§Ù…Ù„
5ï¸âƒ£ **Ø£Ù…Ø± [Ù…ÙˆØ¶ÙˆØ¹]** - Ø£Ù…Ø± Ø§Ø­ØªØ±Ø§ÙÙŠ Ù„Ø£ÙŠ Ù…Ø­ØªÙˆÙ‰
6ï¸âƒ£ **ØªØ¹Ù„ÙŠÙ… [ÙƒÙ„Ù…Ø©]** - Ø¯Ø±Ø³ Ù„ØºØ© Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© ØªÙØ§Ø¹Ù„ÙŠ
7ï¸âƒ£ **Ù‚ØµØ© [Ù…ÙˆØ¶ÙˆØ¹]** - Ø¨Ø±ÙˆÙ…ÙŠØª Ø§Ø­ØªØ±Ø§ÙÙŠ Ù„Ù„Ù‚ØµØ©
8ï¸âƒ£ **ÙƒÙˆØ¯ [Ø·Ù„Ø¨]** - ÙƒØªØ§Ø¨Ø©/ØªØµØ­ÙŠØ­/Ø´Ø±Ø­ Ø§Ù„Ø£ÙƒÙˆØ§Ø¯

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ¨ **Ù…ÙŠØ²Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø©:**

ğŸ“š **ØªÙ„Ø®ÙŠØµ [Ù†Øµ]** - ØªÙ„Ø®ÙŠØµ Ø°ÙƒÙŠ Ù„Ù„Ù†ØµÙˆØµ
ğŸ“ **ÙˆØ§Ø¬Ø¨ [Ø³Ø¤Ø§Ù„]** - Ø­Ù„ Ø§Ù„ÙˆØ§Ø¬Ø¨Ø§Øª Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠØ©
ğŸ¨ **ØªØµÙ…ÙŠÙ… [ÙÙƒØ±Ø©]** - Ø£ÙÙƒØ§Ø± ÙˆØ£ÙˆØ§Ù…Ø± ØªØµÙ…ÙŠÙ…
ğŸ§ª **Ø´Ø±Ø­ [Ù…ÙÙ‡ÙˆÙ…]** - Ø´Ø±Ø­ ØªÙØµÙŠÙ„ÙŠ Ù„Ø£ÙŠ Ù…ÙÙ‡ÙˆÙ…
ğŸŒ **ØªØ±Ø¬Ù… [Ù†Øµ]** - ØªØ±Ø¬Ù…Ø© Ø§Ø­ØªØ±Ø§ÙÙŠØ©
ğŸ¯ **Ø§Ø®ØªØ¨Ø§Ø± [Ù…ÙˆØ¶ÙˆØ¹]** - Ø¥Ù†Ø´Ø§Ø¡ Ø§Ø®ØªØ¨Ø§Ø± ØªÙØ§Ø¹Ù„ÙŠ
ğŸ’¡ **ÙÙƒØ±Ø© [Ù…Ø¬Ø§Ù„]** - Ø£ÙÙƒØ§Ø± Ø¥Ø¨Ø¯Ø§Ø¹ÙŠØ© ÙˆÙ…Ø´Ø§Ø±ÙŠØ¹
ğŸ” **Ø¨Ø­Ø« [Ù…ÙˆØ¶ÙˆØ¹]** - Ù…Ø³Ø§Ø¹Ø¯Ø© ÙÙŠ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¹Ù„Ù…ÙŠ
ğŸ“Š **ØªØ­Ù„ÙŠÙ„ [Ø¨ÙŠØ§Ù†Ø§Øª]** - ØªØ­Ù„ÙŠÙ„ ÙˆØ´Ø±Ø­ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âš™ï¸ **Ø§Ù„ØªØ­ÙƒÙ…:**

ğŸ”„ **Ù…Ø­Ø±Ùƒ openai** - Ø§Ø³ØªØ®Ø¯Ø§Ù… OpenAI
ğŸ”„ **Ù…Ø­Ø±Ùƒ gemini** - Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini
â“ **Ø­Ø§Ù„Ø©** - Ø¹Ø±Ø¶ Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø­Ø§Ù„ÙŠ

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ’¬ Ø£Ø±Ø³Ù„ Ø£ÙŠ Ø³Ø¤Ø§Ù„ ÙˆØ³Ø£Ø³Ø§Ø¹Ø¯Ùƒ!"""

def generate_image_prompt(description, user_id):
    prompt = f"""Ø£Ù†Øª Ù…ØµÙ…Ù… Ø¬Ø±Ø§ÙÙŠÙƒ Ù…Ø­ØªØ±Ù. Ø£Ù†Ø´Ø¦ ÙˆØµÙØ§Ù‹ ØªÙØµÙŠÙ„ÙŠØ§Ù‹ ÙˆØ§Ø­ØªØ±Ø§ÙÙŠØ§Ù‹ Ù„ØµÙˆØ±Ø©: "{description}"

ÙŠØ¬Ø¨ Ø£Ù† ÙŠØªØ¶Ù…Ù†:
1. Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©
2. Ø§Ù„Ø¥Ø¶Ø§Ø¡Ø© ÙˆØ§Ù„Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©
3. Ø§Ù„Ø²Ø§ÙˆÙŠØ© ÙˆØ§Ù„ØªÙƒÙˆÙŠÙ†
4. Ø§Ù„Ù…Ø´Ø§Ø¹Ø± ÙˆØ§Ù„Ø£Ø¬ÙˆØ§Ø¡
5. Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø©
6. Ø£Ù…Ø± prompt Ø§Ø­ØªØ±Ø§ÙÙŠ Ø¬Ø§Ù‡Ø² Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙÙŠ Midjourney Ø£Ùˆ DALL-E

Ù‚Ø¯Ù‘Ù… Ø§Ù„ÙˆØµÙ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø«Ù… Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ù„Ù„Ù€ prompt."""
    
    return safe_generate_content(prompt, "ØªÙˆÙ„ÙŠØ¯ ÙˆØµÙ Ø§Ù„ØµÙˆØ±Ø©", user_id)

def generate_video_guide(topic, user_id):
    prompt = f"""Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ Ø¥Ù†ØªØ§Ø¬ Ø§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª. Ø£Ù†Ø´Ø¦ Ø¯Ù„ÙŠÙ„Ø§Ù‹ Ø§Ø­ØªØ±Ø§ÙÙŠØ§Ù‹ Ø´Ø§Ù…Ù„Ø§Ù‹ Ù„Ø¥Ù†Ø´Ø§Ø¡ ÙÙŠØ¯ÙŠÙˆ Ø¹Ù†: "{topic}"

ÙŠØ¬Ø¨ Ø£Ù† ÙŠØªØ¶Ù…Ù†:
1. **Ø§Ù„ÙÙƒØ±Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©**: Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
2. **Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ**: Ù‡ÙŠÙƒÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ ÙƒØ§Ù…Ù„
3. **Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯**: ÙˆØµÙ ØªÙØµÙŠÙ„ÙŠ (5-7 Ù…Ø´Ø§Ù‡Ø¯)
4. **Ø§Ù„ØªØµÙˆÙŠØ±**: Ù†ØµØ§Ø¦Ø­ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ ÙˆØ§Ù„Ø¥Ø¶Ø§Ø¡Ø©
5. **Ø§Ù„Ù…ÙˆÙ†ØªØ§Ø¬**: Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ù„Ø§Øª ÙˆØ§Ù„Ù…Ø¤Ø«Ø±Ø§Øª
6. **Ø§Ù„Ù…ÙˆØ³ÙŠÙ‚Ù‰**: Ù†ÙˆØ¹ Ø§Ù„Ù…ÙˆØ³ÙŠÙ‚Ù‰ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©
7. **Ø§Ù„Ù†Øµ Ø§Ù„ØµÙˆØªÙŠ**: Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„ØªØ¹Ù„ÙŠÙ‚
8. **Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©**: Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…Ø«Ø§Ù„ÙŠ"""
    
    return safe_generate_content(prompt, "Ø¯Ù„ÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ", user_id)

def generate_presentation(topic, user_id):
    prompt = f"""Ø£Ù†Ø´Ø¦ Ø¹Ø±Ø¶Ø§Ù‹ ØªÙ‚Ø¯ÙŠÙ…ÙŠØ§Ù‹ Ø§Ø­ØªØ±Ø§ÙÙŠØ§Ù‹ Ù…ØªÙƒØ§Ù…Ù„Ø§Ù‹ Ø¹Ù†: "{topic}"

Ø§Ù„Ø¨Ù†ÙŠØ©:
ğŸ¯ Ø§Ù„Ø´Ø±ÙŠØ­Ø© 1: Ø§Ù„Ø¹Ù†ÙˆØ§Ù† ÙˆØ§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„ÙØ±Ø¹ÙŠ
ğŸ“Œ Ø§Ù„Ø´Ø±ÙŠØ­Ø© 2: Ø§Ù„Ù…Ù‚Ø¯Ù…Ø© ÙˆØ§Ù„Ø£Ù‡Ø¯Ø§Ù
ğŸ“Š Ø§Ù„Ø´Ø±Ø§Ø¦Ø­ 3-7: Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ (Ù†Ù‚Ø·Ø© Ù„ÙƒÙ„ Ø´Ø±ÙŠØ­Ø©)
ğŸ’¡ Ø§Ù„Ø´Ø±ÙŠØ­Ø© 8: Ø§Ù„ÙÙˆØ§Ø¦Ø¯ ÙˆØ§Ù„Ù†ØªØ§Ø¦Ø¬
âœ… Ø§Ù„Ø´Ø±ÙŠØ­Ø© 9: Ø§Ù„Ø®Ù„Ø§ØµØ©
â“ Ø§Ù„Ø´Ø±ÙŠØ­Ø© 10: Ø§Ù„Ø£Ø³Ø¦Ù„Ø©

Ø£Ø¶Ù Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ù„Ù„Ø£Ù„ÙˆØ§Ù† ÙˆØ§Ù„Ø®Ø·ÙˆØ· ÙˆØ§Ù„ØªØµÙ…ÙŠÙ…."""
    
    return safe_generate_content(prompt, "Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªÙ‚Ø¯ÙŠÙ…ÙŠ", user_id)

def create_command(topic, user_id):
    prompt = f"""Ø£Ù†Ø´Ø¦ Ø£Ù…Ø±Ø§Ù‹ Ø§Ø­ØªØ±Ø§ÙÙŠØ§Ù‹ (Prompt) Ù…ÙØµÙ„Ø§Ù‹ Ø¹Ù†: "{topic}"

ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ†:
1. ÙˆØ§Ø¶Ø­Ø§Ù‹ ÙˆÙ…Ø­Ø¯Ø¯Ø§Ù‹
2. Ø´Ø§Ù…Ù„Ø§Ù‹ Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¬ÙˆØ§Ù†Ø¨
3. Ù…Ù†Ø¸Ù…Ø§Ù‹ ÙˆÙ…Ù‚Ø³Ù…
4. Ø¬Ø§Ù‡Ø²Ø§Ù‹ Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
5. Ø§Ø­ØªØ±Ø§ÙÙŠØ§Ù‹

Ù‚Ø¯Ù‘Ù… Ø§Ù„Ø£Ù…Ø± Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©."""
    
    return safe_generate_content(prompt, "Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø£Ù…Ø±", user_id)

def teach_english_game(word, user_id):
    prompt = f"""Ø¹Ù„Ù‘Ù… ÙƒÙ„Ù…Ø© "{word}" Ø¨Ø·Ø±ÙŠÙ‚Ø© ØªÙØ§Ø¹Ù„ÙŠØ© ÙˆÙ…Ù…ØªØ¹Ø©:

ğŸ“– Ø§Ù„ÙƒÙ„Ù…Ø© + Ø§Ù„Ù†Ø·Ù‚ Ø§Ù„ØµÙˆØªÙŠ
ğŸ“ Ø§Ù„Ù…Ø¹Ù†Ù‰ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©
ğŸ¯ 3 Ø¬Ù…Ù„ Ù…Ø«Ø§Ù„ÙŠØ©
ğŸ® Ù„Ø¹Ø¨Ø© ØªÙØ§Ø¹Ù„ÙŠØ© Ù„Ø­ÙØ¸ Ø§Ù„ÙƒÙ„Ù…Ø©
ğŸ’¡ Ù†ØµØ§Ø¦Ø­ Ø§Ù„Ø­ÙØ¸
ğŸ”— ÙƒÙ„Ù…Ø§Øª Ø°Ø§Øª ØµÙ„Ø© (Ù…Ø±Ø§Ø¯ÙØ§Øª ÙˆØ£Ø¶Ø¯Ø§Ø¯)"""
    
    return safe_generate_content(prompt, "ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ù„ØºØ©", user_id)

def create_story_prompt(topic, user_id):
    prompt = f"""Ø£Ù†Ø´Ø¦ Ø¨Ø±ÙˆÙ…ÙŠØª Ø§Ø­ØªØ±Ø§ÙÙŠØ§Ù‹ ÙƒØ§Ù…Ù„Ø§Ù‹ Ù„Ù‚ØµØ© Ø¹Ù†: "{topic}"

Ø§Ù„Ø¨Ø±ÙˆÙ…ÙŠØª ÙŠØ¬Ø¨ Ø£Ù† ÙŠØªØ¶Ù…Ù†:
ğŸ­ Ù†ÙˆØ¹ Ø§Ù„Ù‚ØµØ© ÙˆØ§Ù„ÙØ¦Ø© Ø§Ù„Ø¹Ù…Ø±ÙŠØ©
ğŸ‘¥ Ø§Ù„Ø´Ø®ØµÙŠØ§Øª (Ø±Ø¦ÙŠØ³ÙŠØ© ÙˆØ«Ø§Ù†ÙˆÙŠØ©)
ğŸŒ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯ (Ø²Ù…Ø§Ù† ÙˆÙ…ÙƒØ§Ù†)
ğŸ“– Ø§Ù„Ø­Ø¨ÙƒØ© (Ù…Ù‚Ø¯Ù…Ø©ØŒ ØµØ±Ø§Ø¹ØŒ Ø°Ø±ÙˆØ©ØŒ Ø­Ù„)
ğŸ¨ Ø§Ù„Ø£Ø³Ù„ÙˆØ¨ ÙˆÙ†Ø¨Ø±Ø© Ø§Ù„Ø³Ø±Ø¯
ğŸ’¡ Ø§Ù„Ø±Ø³Ø§Ù„Ø© ÙˆØ§Ù„Ø¯Ø±Ø³ Ø§Ù„Ù…Ø³ØªÙØ§Ø¯
âœ¨ Ø¹Ù†Ø§ØµØ± Ø¥Ø¨Ø¯Ø§Ø¹ÙŠØ© ÙØ±ÙŠØ¯Ø©

Ù‚Ø¯Ù‘Ù… Ø§Ù„Ø¨Ø±ÙˆÙ…ÙŠØª Ø¬Ø§Ù‡Ø²Ø§Ù‹ Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙÙŠ ChatGPT Ø£Ùˆ Claude."""
    
    return safe_generate_content(prompt, "Ø¨Ø±ÙˆÙ…ÙŠØª Ø§Ù„Ù‚ØµØ©", user_id)

def code_assistant(request_text, user_id):
    prompt = f"""Ø£Ù†Øª Ù…Ø¨Ø±Ù…Ø¬ Ø®Ø¨ÙŠØ±. Ø³Ø§Ø¹Ø¯ ÙÙŠ: "{request_text}"

1ï¸âƒ£ ÙÙ‡Ù… Ø§Ù„Ø·Ù„Ø¨ ÙˆÙ„ØºØ© Ø§Ù„Ø¨Ø±Ù…Ø¬Ø© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©
2ï¸âƒ£ Ø§Ù„Ø­Ù„: ÙƒÙˆØ¯ ÙƒØ§Ù…Ù„ Ù…Ø¹ ØªØ¹Ù„ÙŠÙ‚Ø§Øª Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
3ï¸âƒ£ Ø§Ù„Ø´Ø±Ø­: ÙƒÙŠÙ ÙŠØ¹Ù…Ù„ Ø§Ù„ÙƒÙˆØ¯
4ï¸âƒ£ Ø§Ù„ØªØ­Ø³ÙŠÙ†: Ù†ØµØ§Ø¦Ø­ ÙˆØ·Ø±Ù‚ Ø¨Ø¯ÙŠÙ„Ø©
5ï¸âƒ£ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±: Ø£Ù…Ø«Ù„Ø© Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…

Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ø£Ø®Ø·Ø§Ø¡: Ø­Ø¯Ø¯Ù‡Ø§ ÙˆØ§Ø´Ø±Ø­Ù‡Ø§ ÙˆÙ‚Ø¯Ù… Ø§Ù„Ø­Ù„."""
    
    return safe_generate_content(prompt, "Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø¨Ø±Ù…Ø¬Ø©", user_id)

def summarize_text(text, user_id):
    prompt = f"""Ù„Ø®Ù‘Øµ Ù‡Ø°Ø§ Ø§Ù„Ù†Øµ Ø¨Ø´ÙƒÙ„ Ø§Ø­ØªØ±Ø§ÙÙŠ: {text}

Ù‚Ø¯Ù‘Ù…:
1. **Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ù‚ØµÙŠØ±** (2-3 Ø¬Ù…Ù„)
2. **Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ù…ØªÙˆØ³Ø·** (ÙÙ‚Ø±Ø©)
3. **Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©** (bullets)
4. **Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©**"""
    
    return safe_generate_content(prompt, "Ø§Ù„ØªÙ„Ø®ÙŠØµ", user_id)

def homework_solver(question, user_id):
    prompt = f"""Ø³Ø§Ø¹Ø¯ ÙÙŠ Ø­Ù„: "{question}"

ğŸ“š Ø§Ù„Ù†Ù‡Ø¬ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ:
1ï¸âƒ£ ÙÙ‡Ù… Ø§Ù„Ø³Ø¤Ø§Ù„ ÙˆØ§Ù„Ù…ÙØ§Ù‡ÙŠÙ…
2ï¸âƒ£ Ø§Ù„Ø´Ø±Ø­ Ø§Ù„ØªÙØµÙŠÙ„ÙŠ Ø¨Ø£Ù…Ø«Ù„Ø©
3ï¸âƒ£ Ø®Ø·ÙˆØ§Øª Ø§Ù„Ø­Ù„ Ø¨Ø§Ù„ØªÙØµÙŠÙ„
4ï¸âƒ£ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
5ï¸âƒ£ Ù†ØµØ§Ø¦Ø­ ÙˆØ£Ø³Ø¦Ù„Ø© Ù…Ø´Ø§Ø¨Ù‡Ø©

ğŸ¯ Ø§Ù„Ù‡Ø¯Ù: Ø§Ù„ÙÙ‡Ù… ÙˆÙ„ÙŠØ³ Ù…Ø¬Ø±Ø¯ Ø§Ù„Ø­Ù„!"""
    
    return safe_generate_content(prompt, "Ø­Ù„ Ø§Ù„ÙˆØ§Ø¬Ø¨", user_id)

def design_ideas(concept, user_id):
    prompt = f"""Ù‚Ø¯Ù‘Ù… Ø£ÙÙƒØ§Ø± ØªØµÙ…ÙŠÙ… Ø´Ø§Ù…Ù„Ø© Ù„Ù€: "{concept}"

ğŸ¨ Ø§Ù„Ù…ÙÙ‡ÙˆÙ… Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹ÙŠ
ğŸ­ Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ø¨ØµØ±ÙŠØ© (Ø£Ù„ÙˆØ§Ù† + Ø®Ø·ÙˆØ·)
ğŸ“ Ø§Ù„ØªØ®Ø·ÙŠØ· ÙˆØ§Ù„ØªÙƒÙˆÙŠÙ†
âœ¨ Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹ÙŠØ©
ğŸ”§ Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©
ğŸ“ Prompts Ø¬Ø§Ù‡Ø²Ø© (Midjourney, DALL-E)

Ù‚Ø¯Ù‘Ù… 3 Ø§ØªØ¬Ø§Ù‡Ø§Øª ØªØµÙ…ÙŠÙ… Ù…Ø®ØªÙ„ÙØ©!"""
    
    return safe_generate_content(prompt, "Ø£ÙÙƒØ§Ø± Ø§Ù„ØªØµÙ…ÙŠÙ…", user_id)

def explain_concept(concept, user_id):
    prompt = f"""Ø§Ø´Ø±Ø­ Ø§Ù„Ù…ÙÙ‡ÙˆÙ… Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø´Ø§Ù…Ù„Ø©: "{concept}"

ğŸ“– Ø§Ù„Ø´Ø±Ø­ Ø§Ù„Ù…Ø¨Ø³Ø· + Ù…Ø«Ø§Ù„ Ù…Ù† Ø§Ù„Ø­ÙŠØ§Ø©
ğŸ” Ø§Ù„ØªØ¹Ù…Ù‚ ÙÙŠ Ø§Ù„ØªÙØ§ØµÙŠÙ„
ğŸ’¡ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ©
ğŸ¯ Ø§Ù„ÙÙˆØ§Ø¦Ø¯ ÙˆØ§Ù„Ø£Ù‡Ù…ÙŠØ©
ğŸ§ª ØªØ¬Ø±Ø¨Ø© Ø£Ùˆ Ù†Ø´Ø§Ø· ØªÙØ§Ø¹Ù„ÙŠ
ğŸ“š Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© ÙˆØ­Ù‚Ø§Ø¦Ù‚ Ù…Ø«ÙŠØ±Ø©"""
    
    return safe_generate_content(prompt, "Ø´Ø±Ø­ Ø§Ù„Ù…ÙÙ‡ÙˆÙ…", user_id)

def translate_text(text, user_id):
    prompt = f"""ØªØ±Ø¬Ù… Ù‡Ø°Ø§ Ø§Ù„Ù†Øµ Ø¨Ø´ÙƒÙ„ Ø§Ø­ØªØ±Ø§ÙÙŠ: {text}

Ù‚Ø¯Ù‘Ù…:
1. Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø­Ø±ÙÙŠØ©
2. Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ©
3. Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹ÙŠØ© (Ø¥Ù† ÙƒØ§Ù† Ø¥Ø¨Ø¯Ø§Ø¹ÙŠØ§Ù‹)
4. Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø«Ù‚Ø§ÙÙŠØ© Ø£Ùˆ Ù„ØºÙˆÙŠØ©

Ø§ÙƒØªØ´Ù Ø§Ù„Ù„ØºØ© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹."""
    
    return safe_generate_content(prompt, "Ø§Ù„ØªØ±Ø¬Ù…Ø©", user_id)

def create_quiz(topic, user_id):
    prompt = f"""Ø£Ù†Ø´Ø¦ Ø§Ø®ØªØ¨Ø§Ø±Ø§Ù‹ ØªÙØ§Ø¹Ù„ÙŠØ§Ù‹ Ø´Ø§Ù…Ù„Ø§Ù‹ Ø¹Ù†: "{topic}"

ğŸ“ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±:
- Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ø£ÙˆÙ„: Ø§Ø®ØªÙŠØ§Ø± Ù…Ù† Ù…ØªØ¹Ø¯Ø¯ (5 Ø£Ø³Ø¦Ù„Ø©)
- Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ø«Ø§Ù†ÙŠ: ØµÙˆØ§Ø¨ Ø£Ùˆ Ø®Ø·Ø£ (5 Ø£Ø³Ø¦Ù„Ø©)
- Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ø«Ø§Ù„Ø«: Ø£Ø³Ø¦Ù„Ø© Ù…Ù‚Ø§Ù„ÙŠØ© (3 Ø£Ø³Ø¦Ù„Ø©)
- Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ø±Ø§Ø¨Ø¹: Ø³Ø¤Ø§Ù„ ØªØ­Ù„ÙŠÙ„ÙŠ (1 Ø³Ø¤Ø§Ù„)

ğŸ¯ Ù…ÙØªØ§Ø­ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª Ù…Ø¹ Ø´Ø±Ø­ ØªÙØµÙŠÙ„ÙŠ
ğŸ“Š Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ØªÙ‚ÙŠÙŠÙ…"""
    
    return safe_generate_content(prompt, "Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±", user_id)

def creative_ideas(field, user_id):
    prompt = f"""Ù‚Ø¯Ù‘Ù… Ø£ÙÙƒØ§Ø±Ø§Ù‹ Ø¥Ø¨Ø¯Ø§Ø¹ÙŠØ© ÙÙŠ: "{field}"

ğŸ’¡ Ø£ÙÙƒØ§Ø± Ù…Ø´Ø§Ø±ÙŠØ¹ (5 Ø£ÙÙƒØ§Ø±):
Ù„ÙƒÙ„ ÙÙƒØ±Ø©:
1. Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø¬Ø°Ø§Ø¨
2. Ø§Ù„ÙˆØµÙ ÙˆØ§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ø¶Ø§ÙØ©
3. Ø§Ù„Ø¬Ù…Ù‡ÙˆØ± Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù
4. Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„ØªÙ†ÙÙŠØ°
5. Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØµØ¹ÙˆØ¨Ø©

ğŸš€ Ø®Ø·ÙˆØ§Øª Ø§Ù„Ø¨Ø¯Ø¡
ğŸ¯ Ù†ØµØ§Ø¦Ø­ Ø§Ù„Ù†Ø¬Ø§Ø­
ğŸŒŸ Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø¥Ù„Ù‡Ø§Ù…"""
    
    return safe_generate_content(prompt, "Ø§Ù„Ø£ÙÙƒØ§Ø± Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹ÙŠØ©", user_id)

def research_helper(topic, user_id):
    prompt = f"""Ø³Ø§Ø¹Ø¯ ÙÙŠ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù†: "{topic}"

ğŸ“š Ø®Ø·Ø© Ø§Ù„Ø¨Ø­Ø« Ø§Ù„ÙƒØ§Ù…Ù„Ø©:
1ï¸âƒ£ Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø¨Ø­Ø«
2ï¸âƒ£ Ø§Ù„Ù…Ù‚Ø¯Ù…Ø© ÙˆØ§Ù„Ù…Ø´ÙƒÙ„Ø© Ø§Ù„Ø¨Ø­Ø«ÙŠØ©
3ï¸âƒ£ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø¨Ø­Ø«ÙŠØ©
4ï¸âƒ£ Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ù†Ø¸Ø±ÙŠ
5ï¸âƒ£ Ø§Ù„Ù…Ù†Ù‡Ø¬ÙŠØ©
6ï¸âƒ£ Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù…Ù‚ØªØ±Ø­
7ï¸âƒ£ Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©
8ï¸âƒ£ Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø²Ù…Ù†ÙŠ"""
    
    return safe_generate_content(prompt, "Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¹Ù„Ù…ÙŠ", user_id)

def data_analysis(description, user_id):
    prompt = f"""Ø­Ù„Ù„ ÙˆÙØ³Ù‘Ø±: "{description}"

ğŸ“Š Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„:
1ï¸âƒ£ ÙÙ‡Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
2ï¸âƒ£ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙˆØµÙÙŠ
3ï¸âƒ£ Ø§Ù„Ø±Ø¤Ù‰ ÙˆØ§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬Ø§Øª
4ï¸âƒ£ Ø§Ù„ØªØµÙˆØ±Ø§Øª Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©
5ï¸âƒ£ Ø§Ù„ØªÙˆØµÙŠØ§Øª"""
    
    return safe_generate_content(prompt, "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", user_id)

def detect_intent(text):
    """Ø§ÙƒØªØ´Ø§Ù Ù†ÙŠØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
    text_lower = text.lower()
    
    if any(w in text_lower for w in ['Ø¹Ù„Ù…Ù†ÙŠ', 'Ø§Ø´Ø±Ø­', 'ÙˆØ¶Ø­', 'Ù…Ø§ Ù‡Ùˆ', 'Ù…Ø§ Ù‡ÙŠ']):
        return 'explain'
    if any(w in text_lower for w in ['ÙƒÙˆØ¯', 'Ø¨Ø±Ù…Ø¬Ø©', 'python', 'code', 'Ø®Ø·Ø£']):
        return 'code'
    if any(w in text_lower for w in ['ØªØµÙ…ÙŠÙ…', 'Ø´Ø¹Ø§Ø±', 'design']):
        return 'design'
    if any(w in text_lower for w in ['ÙˆØ§Ø¬Ø¨', 'Ø­Ù„', 'Ù…Ø³Ø£Ù„Ø©', 'homework']):
        return 'homework'
    if any(w in text_lower for w in ['Ù„Ø®Øµ', 'Ù…Ù„Ø®Øµ', 'summarize']):
        return 'summarize'
    if any(w in text_lower for w in ['ØªØ±Ø¬Ù…', 'translate']):
        return 'translate'
    
    return 'general'

# ========================
# Quick Reply Buttons
# ========================
def get_quick_reply():
    return QuickReply(items=[
        QuickReplyButton(action=MessageAction(label="ğŸ“¸ ØµÙˆØ±Ø©", text="ØµÙˆØ±Ø© ØºØ±ÙˆØ¨ Ø´Ù…Ø³")),
        QuickReplyButton(action=MessageAction(label="ğŸ¬ ÙÙŠØ¯ÙŠÙˆ", text="ÙÙŠØ¯ÙŠÙˆ ØªØ¹Ù„ÙŠÙ…ÙŠ")),
        QuickReplyButton(action=MessageAction(label="ğŸ“– Ù‚ØµØ©", text="Ù‚ØµØ© Ù…ØºØ§Ù…Ø±Ø©")),
        QuickReplyButton(action=MessageAction(label="ğŸ’» ÙƒÙˆØ¯", text="ÙƒÙˆØ¯ Python")),
        QuickReplyButton(action=MessageAction(label="ğŸ“ ÙˆØ§Ø¬Ø¨", text="ÙˆØ§Ø¬Ø¨ Ø±ÙŠØ§Ø¶ÙŠØ§Øª")),
        QuickReplyButton(action=MessageAction(label="ğŸ¨ ØªØµÙ…ÙŠÙ…", text="ØªØµÙ…ÙŠÙ… Ø´Ø¹Ø§Ø±")),
        QuickReplyButton(action=MessageAction(label="âš™ï¸ Ø­Ø§Ù„Ø©", text="Ø­Ø§Ù„Ø©")),
        QuickReplyButton(action=MessageAction(label="ğŸ†˜ Ù…Ø³Ø§Ø¹Ø¯Ø©", text="Ù…Ø³Ø§Ø¹Ø¯Ø©")),
    ])

# ========================
# Webhook
# ========================
@app.route("/callback", methods=['POST'])
def callback():
    signature = request.headers['X-Line-Signature']
    body = request.get_data(as_text=True)
    
    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        logger.error("Invalid signature")
        return "Invalid signature", 400
    except Exception as e:
        logger.error(f"Error in callback: {str(e)}")
        return "Internal error", 500
    
    return 'OK', 200

# ========================
# Message Handler
# ========================
@handler.add(MessageEvent, message=TextMessage)
def handle_message(event):
    user_id = event.source.user_id
    user_msg = event.message.text.strip()
    user_msg_lower = user_msg.lower().replace("Ø£","Ø§").replace("Ø¥","Ø§").replace("Ø¢","Ø§")
    
    logger.info(f"User {user_id}: {user_msg}")
    
    reply_text = ""
    
    try:
        # ØªØ¨Ø¯ÙŠÙ„ Ø§Ù„Ù…Ø­Ø±Ùƒ
        if user_msg_lower.startswith("Ù…Ø­Ø±Ùƒ"):
            engine = user_msg_lower.split()[-1]
            if engine == "openai" and openai_client:
                user_preferences[user_id]["engine"] = "openai"
                reply_text = "âœ… ØªÙ… Ø§Ù„ØªØ¨Ø¯ÙŠÙ„ Ø¥Ù„Ù‰ OpenAI GPT-4"
            elif engine == "gemini" and gemini_model:
                user_preferences[user_id]["engine"] = "gemini"
                reply_text = "âœ… ØªÙ… Ø§Ù„ØªØ¨Ø¯ÙŠÙ„ Ø¥Ù„Ù‰ Google Gemini"
            else:
                reply_text = "âŒ Ø§Ù„Ù…Ø­Ø±Ùƒ ØºÙŠØ± Ù…ØªÙˆÙØ±. Ø§Ù„Ù…Ø­Ø±ÙƒØ§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©:\n"
                if openai_client:
                    reply_text += "- Ù…Ø­Ø±Ùƒ openai\n"
                if gemini_model:
                    reply_text += "- Ù…Ø­Ø±Ùƒ gemini"
        
        # Ø¹Ø±Ø¶ Ø§Ù„Ø­Ø§Ù„Ø©
        elif "Ø­Ø§Ù„Ø©" in user_msg_lower or "status" in user_msg_lower:
            current_engine = user_preferences[user_id]["engine"]
            reply_text = f"""ğŸ“Š **Ø­Ø§Ù„Ø© Ø§Ù„Ø¨ÙˆØª**

ğŸ¤– Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø­Ø§Ù„ÙŠ: {current_engine.upper()}

ğŸ“¡ Ø§Ù„Ù…Ø­Ø±ÙƒØ§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©:
{"âœ… OpenAI GPT-4" if openai_client else "âŒ OpenAI"}
{"âœ… Google Gemini" if gemini_model else "âŒ Gemini"}

ğŸ’¬ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©: {len(user_conversations[user_id])}

âš™ï¸ Ù„ØªØºÙŠÙŠØ± Ø§Ù„Ù…Ø­Ø±Ùƒ:
- Ù…Ø­Ø±Ùƒ openai
- Ù…Ø­Ø±Ùƒ gemini"""
        
        # Ù…Ø³Ø§Ø¹Ø¯Ø©
        elif "Ù…Ø³Ø§Ø¹Ø¯Ø©" in user_msg_lower or "help" in user_msg_lower:
            reply_text = HELP_TEXT()
        
        # ØµÙˆØ±Ø©
        elif user_msg_lower.startswith("ØµÙˆØ±Ø©"):
            desc = user_msg[4:].strip()
            reply_text = generate_image_prompt(desc, user_id) if desc else "âŒ Ø£Ø¶Ù ÙˆØµÙ Ø§Ù„ØµÙˆØ±Ø©\nÙ…Ø«Ø§Ù„: ØµÙˆØ±Ø© ØºØ±ÙˆØ¨ Ø§Ù„Ø´Ù…Ø³"
        
        # ÙÙŠØ¯ÙŠÙˆ
        elif user_msg_lower.startswith("ÙÙŠØ¯ÙŠÙˆ"):
            topic = user_msg[5:].strip()
            reply_text = generate_video_guide(topic, user_id) if topic else "âŒ Ø­Ø¯Ø¯ Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ"
        
        # Ø¹Ø±Ø¶
        elif user_msg_lower.startswith("Ø¹Ø±Ø¶"):
            topic = user_msg[3:].strip()
            reply_text = generate_presentation(topic, user_id) if topic else "âŒ Ø­Ø¯Ø¯ Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø¹Ø±Ø¶"
        
        # Ø£Ù…Ø±
        elif user_msg_lower.startswith(("Ø§Ù…Ø±", "Ø£Ù…Ø±")):
            topic = user_msg[3:].strip()
            reply_text = create_command(topic, user_id) if topic else "âŒ Ø­Ø¯Ø¯ Ù…Ø§ ØªØ±ÙŠØ¯"
        
        # ØªØ¹Ù„ÙŠÙ…
        elif user_msg_lower.startswith("ØªØ¹Ù„ÙŠÙ…"):
            word = user_msg[5:].strip()
            reply_text = teach_english_game(word, user_id) if word else "âŒ Ø­Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø©"
        
        # Ù‚ØµØ©
        elif user_msg_lower.startswith("Ù‚ØµØ©"):
            topic = user_msg[3:].strip()
            reply_text = create_story_prompt(topic, user_id) if topic else "âŒ Ø­Ø¯Ø¯ Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ù‚ØµØ©"
        
        # ÙƒÙˆØ¯
        elif user_msg_lower.startswith("ÙƒÙˆØ¯"):
            req = user_msg[3:].strip()
            reply_text = code_assistant(req, user_id) if req else "âŒ Ø­Ø¯Ø¯ Ù…Ø§ ØªØ­ØªØ§Ø¬Ù‡"
        
        # ØªÙ„Ø®ÙŠØµ
        elif user_msg_lower.startswith(("ØªÙ„Ø®ÙŠØµ", "Ù„Ø®Øµ")):
            text = user_msg[5:].strip() if "ØªÙ„Ø®ÙŠØµ" in user_msg_lower else user_msg[3:].strip()
            reply_text = summarize_text(text, user_id) if text else "âŒ Ø£Ø¶Ù Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø±Ø§Ø¯ ØªÙ„Ø®ÙŠØµÙ‡"
        
        # ÙˆØ§Ø¬Ø¨
        elif user_msg_lower.startswith("ÙˆØ§Ø¬Ø¨"):
            question = user_msg[4:].strip()
            reply_text = homework_solver(question, user_id) if question else "âŒ Ø§ÙƒØªØ¨ Ø§Ù„Ø³Ø¤Ø§Ù„"
        
        # ØªØµÙ…ÙŠÙ…
        elif user_msg_lower.startswith("ØªØµÙ…ÙŠÙ…"):
            concept = user_msg[5:].strip()
            reply_text = design_ideas(concept, user_id) if concept else "âŒ Ø­Ø¯Ø¯ ÙÙƒØ±Ø© Ø§Ù„ØªØµÙ…ÙŠÙ…"
        
        # Ø´Ø±Ø­
        elif user_msg_lower.startswith("Ø´Ø±Ø­"):
            concept = user_msg[3:].strip()
            reply_text = explain_concept(concept, user_id) if concept else "âŒ Ø­Ø¯Ø¯ Ø§Ù„Ù…ÙÙ‡ÙˆÙ…"
        
        # ØªØ±Ø¬Ù…Ø©
        elif user_msg_lower.startswith(("ØªØ±Ø¬Ù…", "ØªØ±Ø¬Ù…Ø©")):
            text = user_msg[4:].strip() if "ØªØ±Ø¬Ù…" in user_msg_lower else user_msg[5:].strip()
            reply_text = translate_text(text, user_id) if text else "âŒ Ø£Ø¶Ù Ø§Ù„Ù†Øµ Ù„Ù„ØªØ±Ø¬Ù…Ø©"
        
        # Ø§Ø®ØªØ¨Ø§Ø±
        elif user_msg_lower.startswith(("Ø§Ø®ØªØ¨Ø§Ø±", "Ø§Ù…ØªØ­Ø§Ù†")):
            topic = user_msg[6:].strip()
            reply_text = create_quiz(topic, user_id) if topic else "âŒ Ø­Ø¯Ø¯ Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±"
        
        # ÙÙƒØ±Ø©
        elif user_msg_lower.startswith("ÙÙƒØ±Ø©"):
            field = user_msg[4:].strip()
            reply_text = creative_ideas(field, user_id) if field else "âŒ Ø­Ø¯Ø¯ Ø§Ù„Ù…Ø¬Ø§Ù„"
        
        # Ø¨Ø­Ø«
        elif user_msg_lower.startswith("Ø¨Ø­Ø«"):
            topic = user_msg[3:].strip()
            reply_text = research_helper(topic, user_id) if topic else "âŒ Ø­Ø¯Ø¯ Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø¨Ø­Ø«"
        
        # ØªØ­Ù„ÙŠÙ„
        elif user_msg_lower.startswith("ØªØ­Ù„ÙŠÙ„"):
            desc = user_msg[5:].strip()
            reply_text = data_analysis(desc, user_id) if desc else "âŒ ØµÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"
        
        # Ø§Ù„Ø±Ø¯ Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ø¹Ø§Ù…
        else:
            intent = detect_intent(user_msg)
            
            if intent == 'explain':
                reply_text = explain_concept(user_msg, user_id)
            elif intent == 'code':
                reply_text = code_assistant(user_msg, user_id)
            elif intent == 'design':
                reply_text = design_ideas(user_msg, user_id)
            elif intent == 'homework':
                reply_text = homework_solver(user_msg, user_id)
            elif intent == 'summarize':
                reply_text = summarize_text(user_msg, user_id)
            elif intent == 'translate':
                reply_text = translate_text(user_msg, user_id)
            else:
                reply_text = safe_generate_content(
                    f"Ø±Ø¯ Ø¨Ø·Ø±ÙŠÙ‚Ø© ÙˆØ¯ÙŠØ© ÙˆÙ…ÙÙŠØ¯Ø© Ø¹Ù„Ù‰: {user_msg}",
                    "Ø§Ù„Ø±Ø¯ Ø§Ù„Ø¹Ø§Ù…",
                    user_id
                )
        
        # Ø­ÙØ¸ Ø§Ù„Ø³ÙŠØ§Ù‚
        add_to_context(user_id, user_msg, reply_text)
        
        # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø±Ø¯
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text=reply_text, quick_reply=get_quick_reply())
        )
        
        logger.info(f"Reply sent to {user_id}")
        
    except Exception as e:
        logger.error(f"Error handling message: {str(e)}")
        error_reply = "âš ï¸ Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.\n\nØ§ÙƒØªØ¨ 'Ù…Ø³Ø§Ø¹Ø¯Ø©' Ù„Ø¹Ø±Ø¶ Ø§Ù„Ø£ÙˆØ§Ù…Ø±."
        
        try:
            line_bot_api.reply_message(
                event.reply_token,
                TextSendMessage(text=error_reply, quick_reply=get_quick_reply())
            )
        except:
            logger.error("Failed to send error message")

# ========================
# Routes
# ========================
@app.route("/", methods=['GET'])
def home():
    engines = []
    if openai_client:
        engines.append("OpenAI GPT-4")
    if gemini_model:
        engines.append("Google Gemini")
    
    return jsonify({
        "status": "running",
        "bot_name": "Ø§Ù„Ø¨ÙˆØª Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠ",
        "version": "3.0",
        "engines": engines,
        "default_engine": DEFAULT_ENGINE,
        "features": [
            "Ù…Ø³Ø§Ø¹Ø¯Ø© - Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£ÙˆØ§Ù…Ø±",
            "ØµÙˆØ±Ø© - ÙˆØµÙ Ø§Ø­ØªØ±Ø§ÙÙŠ Ù„Ù„ØµÙˆØ±",
            "ÙÙŠØ¯ÙŠÙˆ - Ø¯Ù„ÙŠÙ„ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ",
            "Ø¹Ø±Ø¶ - Ø¹Ø±Ø¶ ØªÙ‚Ø¯ÙŠÙ…ÙŠ ÙƒØ§Ù…Ù„",
            "Ø£Ù…Ø± - Ø£ÙˆØ§Ù…Ø± Ø§Ø­ØªØ±Ø§ÙÙŠØ© Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ",
            "ØªØ¹Ù„ÙŠÙ… - Ø¯Ø±ÙˆØ³ Ù„ØºØ© Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©",
            "Ù‚ØµØ© - Ø¨Ø±ÙˆÙ…ÙŠØªØ§Øª Ù„Ù„Ù‚ØµØµ",
            "ÙƒÙˆØ¯ - Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø¨Ø±Ù…Ø¬Ø©",
            "ØªÙ„Ø®ÙŠØµ - ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù†ØµÙˆØµ",
            "ÙˆØ§Ø¬Ø¨ - Ø­Ù„ Ø§Ù„ÙˆØ§Ø¬Ø¨Ø§Øª",
            "ØªØµÙ…ÙŠÙ… - Ø£ÙÙƒØ§Ø± Ø§Ù„ØªØµÙ…ÙŠÙ…",
            "Ø´Ø±Ø­ - Ø´Ø±Ø­ Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ…",
            "ØªØ±Ø¬Ù… - ØªØ±Ø¬Ù…Ø© Ø§Ø­ØªØ±Ø§ÙÙŠØ©",
            "Ø§Ø®ØªØ¨Ø§Ø± - Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª ØªÙØ§Ø¹Ù„ÙŠØ©",
            "ÙÙƒØ±Ø© - Ø£ÙÙƒØ§Ø± Ø¥Ø¨Ø¯Ø§Ø¹ÙŠØ©",
            "Ø¨Ø­Ø« - Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¹Ù„Ù…ÙŠ",
            "ØªØ­Ù„ÙŠÙ„ - ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª",
            "Ù…Ø­Ø±Ùƒ - ØªØ¨Ø¯ÙŠÙ„ Ø§Ù„Ù…Ø­Ø±Ùƒ",
            "Ø­Ø§Ù„Ø© - Ø¹Ø±Ø¶ Ø§Ù„Ø­Ø§Ù„Ø©"
        ]
    }), 200

@app.route("/health", methods=['GET'])
def health():
    return jsonify({
        "status": "healthy",
        "openai": "available" if openai_client else "unavailable",
        "gemini": "available" if gemini_model else "unavailable"
    }), 200

# ========================
# Run App
# ========================
if __name__ == "__main__":
    port = int(os.environ.get("PORT", 5000))
    logger.info(f"ğŸš€ Starting bot on port {port}")
    logger.info(f"ğŸ¤– Default engine: {DEFAULT_ENGINE}")
    app.run(host="0.0.0.0", port=port, debug=False)
